CNN 歷史

整理不錯的網站
	https://medium.com/ching-i/卷積神經網絡-cnn-經典模型-lenet-alexnet-vgg-nin-with-pytorch-code-84462d6cf60c
    https://medium.com/ching-i/卷積神經網絡-cnn-經典模型-googlelenet-resnet-densenet-with-pytorch-code-1688015808d9

Backbone :  extract feature
Neck :      multiscale
Head :      different task

< Backbone >
    主要用這個比較 ImageNet LSVRC / ILSVRC / ImageNet Large Scale Visual Recognition Challenge
        
LeNet (1998)
    卷積神經網路的始祖

AlexNet (2012) (2012 年 ImageNet LSVRC 競賽中 冠軍)
        https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf
    Maxpooling, 也因此 stride 可以小於 size
    ReLU 替代 tanh/Sigmoid 
    加入 Dropout 
    對 RGB 通道做主成分分析 (PCA)，接著使用高斯擾動，對顏色、光照做變換

VGG (2014) (2014 年 ImageNet LSVRC 分類競賽中 亞軍)
        https://arxiv.org/pdf/1409.1556.pdf
    Very deep convolutional networks for large-scale image recognition.
    更多 layer 的網路架構
    且改用小卷積核

    VGGNet 最具代表性的是 VGG16
        五個卷積區塊 + 三個全連接層
            其中前兩個卷積層內含 2 個基礎模組、後三個卷積層內含 3 個基礎模組，
            總共為 2x2 + 3x3 + 3 = 16 層網路層數

NiN (Network in Network) (2014)
        https://arxiv.org/pdf/1312.4400
    MLP 卷積層 (Mlpconv)
        要提取的特徵 是 高度非線性的
        因此在每個局部感受野中加入更複雜的神經網路來運算
    首次提出 1x1 卷積層
        做 channel 間的線性組合
        增加非線性，因為可以接 activation
        降維或升維
        提升表達能力但計算成本低
    Global Average Pooling (GAP)
        每個 channel 的 spatial 平均值
            減少大量參數
            降低 overfitting

GoogLeNet (Inception-V1，2014) (2014 年 ImageNet LSVRC 分類競賽中 冠軍)
    受到 NiN 啟發
        把多個不同大小的卷積層組合 並把運算結果合併 
    分類輔助器 (Auxiliary Classifiers）
        優點
            解決深層神經網路的梯度消失問題
            regularization 效果
        結構
            在網路的中間層額外接出的「小型分類器」
            這些輔助器會根據標籤（Ground Truth）計算自己的 Loss
            訓練時的最終損失函數是主路徑損失與輔助路徑損失的加權總和
                訓練後會被移除
        未來
            被 Batch Normalization（批次標準化）與 ResNet（殘差連接）取代

201510 ResNet (2015 年 ImageNet LSVRC 分類競賽中 冠軍)
    Deep Residual Learning for Image Recognition
        https://doi.org/10.48550/arXiv.1512.03385

    發明了 Residual Learning, 
        解決深層網路隨深度增加反而退化的 degradation problem
            也就是解決了深層網路 中 淺層網路的梯度消失問題
        Shortcut Connection : Prev_x + this_x = output_x
            當訓練達到飽和的時候, this_x 的輸出會變成 0
                也就是這個 node 學到 輸出為0 (identity mapping) 反而是最佳解
            也就是 Prev_x 的結果 會直接傳到 output_x
                梯度數值能夠直接回傳至淺層

201611 ResNeXt 
	Aggregated Residual Transformations for Deep Neural Networks
        https://doi.org/10.48550/arXiv.1611.05431
    ResNet 結合了 Inception 的結構
	https://medium.com/ching-i/resnext-論文閱讀-7898b1281ef3

201608 DenseNet 
    Densely Connected Convolutional Networks
        https://doi.org/10.48550/arXiv.1608.06993
    更複雜化 ResNet 的 Shortcut Connection
        ResNet只是在block的最頂端拉一條線出來，DenseNet是直接讓每一層的輸出 concat 到之後的每一層
            從低階特徵到高階特徵都會被直連到最後一層卷積層，這讓下一層接受到更全面的圖像資訊
        比起 GoogLeNet 加寬又加深，DenseNet 變成增加 channel
    效果 
        更加減緩梯度消失問題
        上面提到的 可以看到低階到高階的特徵
        減少參數量!
            那是因為對於舊的特徵圖(feature-map)是不需要再去重新學習的
            而且因為 growth-rate 不用設很大，所以減少許多參數。
            這並不對應計算量與使用空間會縮小 ! 
                因為最後一層要計算 每一層加起來的特徵 所以其實計算量跟記憶體是需要很大的

FPN (Feature Pyramid Network) (Neck)
    為了同時看清楚 大物體 與 小物體
    但是第一次使用是用在 Faster R-CNN 上

2019 EfficientNet
    最優化 scaling, depth, width, resolution 之間的關係

< Head > -------------------------------------------------------------------------------
OverFeat (2013)
    發明 滑動窗口（Sliding Window) 的高效實現方式
    對輸入圖像進行不同偏移的採樣
        確保網絡能捕捉到更細微的空間資訊
    全卷積化（FCN 的雛形）
        避免對重疊區域的重複計算
    
R-CNN (2014)
    region proposal-based 
        每次只會計算被 propose 的 region
        但這是靠 外部演算法(Selective Search) 才能生成建議區域

SPPnet (Spatial Pyramid Pooling Network) 
    會先將整張圖先跑一次 CNN 得到特徵圖
        避免每個 proposal 都重跑 CNN
        而是在 shared feature map 上做 pooling
    Spatial Pyramid Pooling Layer (多尺度金字塔)
        解決 CNN全連接層 要求固定尺寸的輸入 > 會導致物體變形
        原理: 不論輸入的特徵區域大小如何，SPP 層會將其劃分為固定的格數（例如 4*2, 2*2, 1*1）。
        對每個格子進行 Max Pooling，最終產生的向量長度固定

Fast R-CNN
    RoI Pooling (單尺度)
        只是把 Spatial Pyramid Pooling Layer 改成單一尺度(7*7)

Faster R-CNN (2015 end)
    RPN (Region Proposal Network)
        替換原本的 Selective Search
        RPN 直接在特徵圖上滑動，利用 Anchor Boxes（錨點框）機制，直接預測哪裡有物體

SSD (Single Shot MultiBox Detector)
    one stage detector
        在不同 feature map scale 上直接預測 bbox
        使用 default boxes，也就是 anchor

FPN + Faster R-CNN (2017)
    看 FPN

< YOLO > - 為了速度
YOLO v1 (2015) 
    概念
        把 影像 分隔成多個格子
        每個格子獨自預測 (是什麼 y0, y1, y2 ..., 
                        兩個候選框 
                            中心位置距離左上角的偏移量 X1, Y1, 相對於整張影像的比例 W1, H1, Confidence P1
                            中心位置距離左上角的偏移量 X2, Y2, 相對於整張影像的比例 W2, H2, Confidence P2)
            limitation : one cell can only detect one object
            priors = 2 : 兩個候選 box 
        為什麼 loss 要全部加起來，這樣我怎麼知道 是哪一個 label 造成的 loss ??
        最後有一個 7*7*30 的全連接層 為什麼 7*7 一定會是各個 grid 的結果 ??

YOLO v2 (2016)    
    https://arxiv.org/pdf/1612.08242
    Batch Normalization
        捨棄 Dropout (因為沒有全連接層)
        換用 Batch Normalization
            對每一層的輸出都做 Normalization
    High Resolution Classifier 更大的解析度
        先用 224*224 訓練
        再用 448*448 進行 10 次的訓練微調
    Convolutional With Anchor Boxes
        Anchor Boxes 有助於 recall 的提升
        在這裡 Anchor Boxes == priors 
    Dimension Clusters
        用 k-means 找 priors (best value k = 5)
            run k-means clustering on the training set bounding boxes
            k-means 所用的距離公式 : 1 - IOU(box, centroids)
    Direct location prediction
        v1 預測偏移量 會導致收斂問題
        v2 改成使用 在這個grid中是 什麼位置 
            若 X, Y 都為 0.5 : 代表在中心點
            若 X, Y 都為 0   : 代表在左上角
            real_x = σ(output_x) + center_x (center_x 是這個 grid 從左數來第幾個)
            real_w = prior_w * exp(output_w)
                這些單位是網格單位，所以不用再乘上邊長
    Fine-Grained Features
        DownSample 是直接拆分
            原圖大小 2X*2X 直接拆分成 X*X 然後 channel 變成 4 倍
    Backbone : DarkNet19 (VGG+Resnet)
        移除了 FCL
        只包含卷積層, 也就是 Fully Convolutional Network, FCN
            也就是說能夠輸入任何大小的圖像 (Multi-Scale Training)
        所以最後 Grid 大小並不是固定的
            會根據 input shape 變化
            但 Direct location prediction 資訊長度是相同的
                因為有 1*1 的卷積層 可以調整 channel 數量

YOLO v3 (2018)
    https://arxiv.org/pdf/1804.02767
    升級 DarkNet
        不同 scale 預測不同大小的物件
            因此更適合小物件偵測
    priors 改成 9 種 (也是 Dimension Clusters 方法)
        3種scale 有"各自"不同的 3種大小的 priors
    softmax 改進，因此可以預測多標籤的任務
        EX: 這個物件同時是 狗, 吉娃娃, 動物

-- 換作者 --   
            

    


YOLO v4 (2020)
    https://arxiv.org/pdf/2004.10934
    架構
        Weighted-Residual-Connections (WRC)
        Cross-Stage-Partial-connections (CSP)
        Cross mini-Batch Normalization (CmBN)
        Self-adversarial-training (SAT)
        Mish-activation
    Backbone :  extract feature
    Neck :      multiscale
    Head :      different task

YOLO v7
    ELAN（Efficient Layer Aggregation Network）

YOLO v8 (2022)
    https://arxiv.org/pdf/2501.13400
    Backbone : 
        C2f block
            旨在改進 
            在保持輕量化的同時，獲得更豐富的梯度流（Gradient Flow）資訊
                結合 YOLOv5 中 C3模組 的優點
                參考了 YOLOv7 中 ELAN 的結構思想
            架構
                1*1 卷積
                Split 切分：將輸出特徵圖切分為兩個部分
                    堆疊 Bottleneck：其中一個分支會經過一系列的 Bottleneck 運算層
                多路徑融合：C2f 會將每個 Bottleneck 的輸出都進行 Concatenate（連接），而不僅僅是最後一層的輸出。
                1*1 卷積 : 特徵整合回原始通道數
    
        Conv block
            Conv2d
            BatchNorm2d
            SILU : activation function
    Neck : 
        SPPF (Spatial Pyramid Pooling Fast)
        C2f block
        Upsample
    Head : anchor free
        predict happend in the grid cell


        


multiscale context aggregation convolutional neural network (MCACNN) 



-- < tech term > ---------------------------------------------------
ConvNet : 泛指所有 CNN
stride : kernel shift distance

Kernel == Filter

Concat (Concatenation) 
    只是維度拼接,沒有任何運算
    為了特徵多樣性 (特徵會從不同 Layer 過來)
    EX:
        feature data 1 大小是 H*W*C1
        feature data 2 大小是 H*W*C2
        Concat 之後大小就是 H*W*(C1+C2)

DownSample
    Max pooling
    Average Pooling
    Strided Convolution
UpSample
    Nearest Neighbor Interpolation : 直接複製像素
    Bilinear Interpolation : 平滑版本
    Transposed Convolution
    Sub Pixel Convolution
    上採樣 + Conv
    Padding : 如果尺寸差異極小 就直接補0
        

Growth-rate
    每一層會新增多少個 feature channel (k)
        == DenseNet 每一層會新增的 feature map 數量
    是 hyperparameter 