< 題目類型 > ------------------------------------------------------
一定是 "找一個 function, 讓 某個loss function minimum"
但根據 function 的不同就有不同的名稱

Continuous 的結果
    Linear regression : 
        預估
            單個 data : XᵀB = Y'
                function 形式 : y' = b0 + b1*x1 + b2*x2 + ... + bn*xn = XᵀB (linear 的定義)
                    輸出 y 是一個數字 
            data 陣列 : XB = Y'
        真實
            單個 data : XᵀB + E = Y
            data 陣列 : XB  + E = Y
        Linearity 是指對參數 B 的線性組合，而不是對特徵 x。
            即使特徵是 x^2 或 log(x)
            只要公式長得像 b_1(feature_1) + b_2(feature_2)
            它在統計學上就屬於 線性回歸。
Discrete 的結果 (classification)
    Logistic regression : 
        function 形式 : y = sigmoid(XᵀB)
            輸出落在 0 到 1 的機率，也就是為了要 classification
        Logistic regression func can be expressed as the log odds
            log( p(x) / (1-p(x)) ) = B0 + B1 X
            p(x) = 1 / (1 + e^-(B0 + B1 X)) ... which is sigmoid equation
                but there is no close solution, and this function is not convex function
                so the only way to solve it is through MLE

< 找解答的方法 > ------------------------------------------------------
Ordinary Least Squares (OLS)
    如果是 linear regression : XᵀB = Y
    可以用 Ordinary Least Squares (OLS) 計算 MSE 的最佳擬合線的方法
        B = (XᵀX)^-1 Xᵀy
    目標 :
        argB min( (y-y')^2 )
    推導方法1 (幾何) :
        我們要讓 |y-y'| 最小
        也就是殘差向量 y-y' 必須與 X 的每一個列向量都相互垂直 (垂直距離才會最短)
        要找 Xᵀ(y-y') = 0 ( Xᵀ 是因為是內積的概念 )
            Xᵀ(y-XB) = 0
            Xᵀy-XᵀXB = 0
            Xᵀy = XᵀXB
            B = (XᵀX)^-1 Xᵀy
    推導方法2 (微分) :
        Loss = (y-y')^2
            = ||(y-XB)||^2
            = (y-XB)ᵀ(y-XB)
        展開 = yᵀy - 2yᵀXB + (XB)ᵀXB
        做 Gradient descent

Gradient descent : 對每個 var 做偏微分
    if it's a "convex function", then Gradient Descent is good enough
        since the minimum is guaranteed to be the global minimum

    stochastic gradient descent (SGD)
        每次只使用一筆 data 做 gradient descent
            有 引入了隨機噪聲 == 正則化 的效果

Maximum likelihood estimation (MLE)
    by maximizing the likelihood of observing a given set of data under the assumed statistical distribution
    找到一組參數，讓這組參數下「產生出目前觀察到的數據」的機率（概似度）達到最大
        所以 ML 才用 L(θ|x) (參數θ 才會在前面)
            θ 包含了所有的權重（weights）與偏差（bias）
    通常都會對 likelihood functiion 取 log (比較好計算), 並且假設 xi 之間是獨立的
        log L(θ) = log MUL( p(xi | θ) )
                    = sum( log p(xi | θ) )

Expectation maximization (EM)
    視覺化 : https://youtu.be/rVfZHWTwXSA?si=mrJCaVkoKsfPqXMX&t=3634
    E-step / E step (forward) : guess the value of z, use it to calculate the log likelihood
    M-step / M step (backward): use the estimate value of the z to update the parameters
    Expectation Lower Bound (ELBO / ELBo)

constraint optimization
    套用 Lagrange 轉換成線性代數形式，再用其他方法求解


    
但有沒有 close function 跟是不是 convex function 沒有相互關係
        
< 轉換問題 > ------------------------------------------------------
tech term
    primal problem : 原本你一開始要解的最佳化問題
    dual problem   : 轉換後的問題
        dual version 一定是 convex optimization problem (下面影片有講解)
    strong duality : 
        primal optimal value = dual optimal value
        strong duality 需要滿足以下條件
            問題是 convex
            滿足 Slater's condition
    weak duality
        對 primal 是 minimization 問題來說
            primal optimal value >= dual optimal value
            在優化中 dual 會變成 lower bound
                只要 Maximize( lower bound 也就是 dual problem )
                下界（Dual）推到最高，它就會最接近（甚至等於）Primal 的最小值
        對 primal 是 maximization 問題來說
            上面全部反過來
            
Lagrange : can make constraint into unconstraint problem
    使用情況: maximize or minimize under some constraints
    Lagrange 轉換前原本題目:
        minimize f(x) s.t. g(x) <= 0 and h(x) = 0
            minimize f(x)
                如果是 Maximization 那就改成 -f(X)
            +/- g(x) <= 0
                如果代常數
                    g(x) <= C 要轉換成 g(x) - C <= 0, g(x) - C 會變成新的 g(x)
                +/- 都行
                    + g(x) = -( -g(x) ), -g(x) 會變成新的 g(x)
    轉換後的式子
        L = f(x) +/- (λ1*g1(x) + λ2*g2(x) + ... + v1*h1(x) + v2*h2(x) + ...)
            λ, v 叫做 Lagrange multipliers, 且一定 >= 0
                λ, v 如果等於0, 代表 這個限制沒有起到限制作用 (最低點在限制範圍之內)
                λ, v 如果大於0, 代表 這個限制  有起到限制作用 (最低點在限制範圍之外)
    全域最佳解的條件 (否則只是局部的):
        f(x) 是 convex
        g(x) 是 convex
        h(x) 是 affine (線性 + 位移)
        滿足 constraint qualification
    轉換後的好處
        如果滿足全域最佳解條件，KKT 條件即為最優解的充分必要條件。
        這意味著只要你解出符合 KKT 的點，它保證就是全域最小值。
    找 Lagrange 最佳解的方法 1 : 如果是 convex function，可以直接微分
    找 Lagrange 最佳解的方法 2 : 
    KKT conditions (Karush–Kuhn–Tucker conditions)
        使用情況: 幫轉換後的 Lagrange unconstrained problem 找最佳解
        KKT conditions :
            Stationarity : L 對所有的變數做偏微分 = 0
            Complementary slackness : 全部的 λi*gi(x) 式子 = 0
                代表 λi 或 gi(x) 其中一定有一個是 0
            Primal feasibility : gi(x) <= 0, h(x) = 0
            Dual Feasibility   : λi >= 0
        轉換後: 
            0 == ∂L/∂x1 == ∂L/∂x2 ... == ∂L/∂λ1 == ∂L/∂λ2 ... == ∂L/∂v1 == ∂L/∂v2 ...
            0 == λ1*g1(x) == λ2*g2(x) ...
            gi(x) <= 0
            hi(x) == 0
            λi >= 0
        步驟 :
            因為 Complementary slackness
            只對 λi == 0 或 gi(x) == 0 進行 Case 討論
                case 1 : λ1 = 0, λ2 = 0 帶入 其他條件
                case 2 : g1(x) = 0, λ2 = 0 帶入 其他條件
                ...
                一定會有一個正確的 case
    找 Lagrange 最佳解的方法 3 : 
    Primal Problem (這個演算法也是從 KKT 導出來的)
        將"約束"轉化為"Min-Max 形式"
            我們想要讓 Lagrange 當違反條件時，會產生無窮大的解
                (當 g(x) 或 h(x) > 0, 只要 λ 或 v 只要設成無限大, 整個式子就會變無限大)
                所以裡面一定是 Maxλv(L)
            我們想要讓全部的解都不要違反條件
                所以判斷全部的解的最小值就好了 
                (只要這個值不是無限大 那其他就不是無限大)
                所以外面一定是 Min() > Min(Maxλv(L))
            p* = Min(Maxλv(L))
        p* 有一個 dual version
            d* = Maxλv(Min(L))
        使用 d* 找到 p* 的最佳解
    推薦影片 : https://youtu.be/ZX_baiqXhoE?si=n7lnVYS4JQM9PS7t&t=1434
    
        

