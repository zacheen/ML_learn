< Probabilistic graphical model (PGM) > ------------------------------------------------
├─ Directed graphical model (由圖表示的概率分佈) (Directed Probabilistic Graphical Models)
│ └─ Hidden Markov Models (HMM) (generative)
│ └─ Bayesian network
│ └─ Kalman filter
│
└─ Undirected graphical model (表示一個聯合概率分佈) (Undirected Probabilistic Graphical Models)
  └─ Markov Random Field (MRF)
        很多人會說 Undirected graphical model == Markov Random Field
  └─ CRF (discriminative) 
        有點像是 MRF 的 特殊版本

Conditional Random Field (CRF)
    用在序列資料上的機率模型
        常見於 NLP, 序列標註任務(EX:詞性標註、命名實體辨識、分詞)
    P(Y|X)
    任務 :
        在所有可能的標籤序列中找出「整體最合理」的一整串標籤
        也就是 最大化 log P(Y|X)
    解法:
        Viterbi algorithm
    
Markov chain
    is a model that tells us something about the probabilities of sequences of random variables, states, each of which can take on values from some set.
        predict the probabilities based on previos sequences
    這裡的 Assumption : 
        first order : 我只看前一個 state 去推論下一個 state
    目的 :
        想要計算在第 inf 次，各個東西出現的機率
    步驟 :
        先轉成 transition matrix, 每格會對應到 從 X 變成 X' 的機率
                A'  B'  C'
            A   0.2 0.6 0.2
            B   0.3 0.0 0.7
            C   0.5 0.0 0.5
            性質
                當 T^2 這裡面的數值會變成 : 剛好兩步 從 X 變成 X' 的機率
        還需要 initial state 的機率 
            假設 initial state 為 B
            π0 = [0, 1, 0]
        當前一個 state * transition matrix = 下一個 state 的機率
            [0, 1, 0] * [ 0.2 0.6 0.2   = [0.3, 0.0, 0.7]
                          0.3 0.0 0.7
                          0.5 0.0 0.5 ]
        總有一個 state 經過 transition matrix 轉換後 還是相同的 : 這就是 stable state(π)
            π*T = π -> π(T-I) = 0
            再加上 Σ πi = 1
                EX: 上述的 case
                x(0.2-1) + y(0.3) + z(0.5) = 0
                x(0.6) + y(0.0-1) + z(0.0) = 0
                x(0.2) + y(0.7) + z(0.5-1) = 0
                x + y + z = 1 (必要條件，用來替換掉上述其中一條相依的方程式)
                解出來 π = [0.35211, 0.21127, 0.43662]
    term :
        Transient State : the state of π probability == 0  (一旦離開了這個狀態，有可能永遠回不來)
            if there are some Transient State, the graph is reduceible
        Recurrent State : the state of π probability != 0
Hidden Markov Models (HMM)
    P(X, Y)
    term :
        Hidden status     : transition matrix 也就是 H 變成 H' 的機率
        Observed variable : 可以獲取的 data
        Emission Matrix : Hidden status 對應到 Observed variable 的機率
                O1  O2 
            H1  0.9 0.1
            H2  0.6 0.4
            H3  0.2 0.8
    HMM 的三大問題 (The Three Problems)
        Likelihood problem
            給定模型參數  和觀察序列 O，計算這個序列出現的機率 P(O|transition matrix)
            意義 : regardless
            ??
            
        Decoding
            given an observation sequence O and ... discover the best hidden state sequence
            我們現在有 Observed variable 請問 Hidden status 機率最高的 sequence 是什麼?
            <步驟>
            首先推導出各個 組合的 機率    
                = argmax P(H = h1, h2, ..., hn | O = o1, o2, ..., on)
                = argmax P(H | O)
                帶入 Bayes
                = argmax P(O | H) * P(H) / P(O)
                用下面兩個 取代無法算出的 P
                    P(O | H) = P(o1 | h1) * P(o2 | h2) * ... * P(on | hn) = Π_n P(oi | hi)
                    P(H) = Π_n P(hi | hi-1)
                = argmax Π_n P(oi | hi) * (hi | hi-1) ... 這些都是表中可以查詢到的值
            再使用 Viterbi algorithm 計算出各個組合對應的機率
                
        Learning
            given an ob and the set of states in the HMM, how to learn the parameters trasition probability and e... probability
            ??
            Bean search